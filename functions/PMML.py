import os
from enum import Enum
import pandas as pd
import pypmml
import sklearn.metrics as sklearn_metrics
from sklearn.cluster import KMeans
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.neural_network import MLPClassifier, MLPRegressor
from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor
import xml.etree.ElementTree as ElementTreeXML

from helpers.logger import print_and_log

# Define error tolerance as a constant
EPSILON = 1e-1


class ModelName(Enum):
    NAIVE_BAYES = "naive bayes"
    DECISION_TREE = "decision tree"
    LINEAR_REGRESSION = "linear regression"
    MLP = "multi-layer perceptron (Neural Network)"
    K_MEANS = "k-means"


class PMMLModel:
    """
    PMML model class to make predictions, save the predictions and metrics to a parquet file and validate the model

    Attributes:
    ----------
    outputDatasetFilePath: str
        Output dataset filepath
    pmml_model_filepath: str
        PMML model filepath
    export_test_metrics_path: str
        Export test metrics path
    inputDataset: pd.DataFrame
        Input dataset
    inputDatasetTest: pd.DataFrame
        Input dataset for testing
    predictions: pd.DataFrame
        Predictions made by the model
    validation_predictions: pd.DataFrame
        Predictions to validate the model
    pmmlModelLearner: pypmml.Model
        PMML model learner
    exportOnlyPredictions: bool
        Export just the predictions or the whole dataset with predictions
    export_test_metrics: bool
        Export the test metrics or not
    algorithmName: str
        Algorithm type name
    modelName: ModelName
        Algorithm model name
    inputNames: list
        Input column names used by the model
    outputNames: list
        Output column names generated by the model
    predictedClassColumn: str
        Predicted class column name
    classColumn: str
        Class column name to predict
    metric_scores: pd.DataFrame
        Metric scores
    train_split: float
        Train split percentage for the dataset
    test_split: float
        Test split percentage for the dataset
    """
    outputDatasetFilePath: str = None  # Output dataset filepath
    pmml_model_filepath: str = None  # PMML model filepath
    export_test_metrics_path: str = None  # Export test metrics filepath

    inputDataset: pd.DataFrame = None  # Input dataset
    inputDatasetTest: pd.DataFrame = None  # Input dataset for testing
    predictionsTest: pd.DataFrame = None  # Predictions made by the model
    validation_predictions: pd.DataFrame = None  # Validation predictions

    pmmlModelLearner: pypmml.Model = None  # PMML model learner
    exportOnlyPredictions: bool = None  # Export just the predictions or the whole dataset with predictions
    export_test_metrics: bool = None  # Export the test metrics or not

    algorithmName: str = None  # Algorithm type name
    modelName: ModelName = None  # Algorithm model name

    inputNames: list = None  # Input column names used by the model
    outputNames: list = None  # Output column names generated by the model

    predictedClassColumn: str = None  # Predicted class column name
    classColumn: str = None  # Predicted class column name

    metric_scores: pd.DataFrame = None  # Metric scores
    metric_scores_numeric: pd.DataFrame = None  # Metric scores in numeric format

    train_split: float = None  # Train split percentage for the dataset
    test_split: float = None  # Test split percentage for the dataset

    def __init__(self, input_dataset: pd.DataFrame, output_dataset_filepath: str, model_learner_pmml_filepath: str,
                 export_only_predictions: bool, export_test_metrics: bool, train_split: float = None,
                 test_split: float = None, export_test_metrics_path: str = None):
        """
        Initialize the PMML model object, parse the PMML model and make and export the predictions

        :param input_dataset: dataframe with the input dataset
        :param output_dataset_filepath: filepath to the output dataset to save the predictions and metrics
        :param model_learner_pmml_filepath: filepath to the PMML model file
        :param export_only_predictions: export just the predictions or the whole dataset with predictions
        :param export_test_metrics: boolean to export the test metrics or not
        :param train_split: train split percentage for the dataset
        :param test_split: test split percentage for the dataset
        :param export_test_metrics_path: filepath to export the test metrics
        """
        self.outputDatasetFilePath = output_dataset_filepath
        self.pmml_model_filepath = model_learner_pmml_filepath
        self.export_test_metrics_path = export_test_metrics_path

        self.inputDataset = input_dataset  # Load the input dataset dataframe
        self.pmmlModelLearner = pypmml.Model.load(model_learner_pmml_filepath)  # Load the PMML model
        self.exportOnlyPredictions = export_only_predictions  # Export just the predictions or the whole
        # dataset with predictions
        self.export_test_metrics = export_test_metrics  # Export the test metrics or not
        # Save the train and test split if they are not None
        if train_split is not None and test_split is not None:
            self.train_split = train_split
            self.test_split = test_split

        # MAIN FUNCTION CALLS: PARSE PMML MODEL, MAKE AND EXPORT PREDICTIONS AND SAVE TEST METRICS
        self.parser_pmml_model()  # Parse the PMML model
        self.make_and_export_predictions()  # Make and export the predictions
        self.save_test_metrics()  # Save the test metrics
        print_and_log(f"{self.modelName.value.upper()} model has been loaded\n")

    def get_model_name(self):
        """
        Get a uniform model name from the PMML model name
        """
        if self.pmmlModelLearner.modelName is not None:
            pmml_model_name = self.pmmlModelLearner.modelName
        else:
            pmml_model_name = self.pmmlModelLearner.modelElement
        model_name_lower = pmml_model_name.lower()
        best_match = None
        highest_score = 0

        # Calculate the score based on substring matches with variable lengths
        for name in ModelName:
            name_value = name.value.lower()
            score = 0

            # Iterate through all possible substrings of name_value
            for i in range(len(name_value)):
                for j in range(i + 1, len(name_value) + 1):
                    substring = name_value[i:j]
                    if substring in model_name_lower:
                        score += 1

            # Save the best match
            if score > highest_score:
                highest_score = score
                best_match = name

        self.modelName = best_match

    def parser_pmml_model(self):
        """
        Parse the PMML model
        """
        self.algorithmName = self.pmmlModelLearner.functionName  # Get the function name
        self.get_model_name()
        self.inputNames = self.pmmlModelLearner.inputNames
        self.outputNames = self.pmmlModelLearner.outputNames

        # Get the predicted class column name
        if self.algorithmName != 'clustering':
            self.predictedClassColumn = self.outputNames[0]  # Get the predicted class column name
            self.classColumn = self.predictedClassColumn.replace('predicted_', '')  # Get class column name

    def make_and_export_predictions(self):
        """
        Make and export the predictions
        """
        print_and_log(f"Making predictions on the dataset using {self.modelName.value.upper()} model...")
        # Split the dataset into train and test using train_test_split from sklearn
        y_test = None
        y_train = None
        if self.classColumn is not None:
            x_train, x_test, y_train, y_test = train_test_split(self.inputDataset[self.inputNames],
                                                                self.inputDataset[self.classColumn]
                                                                if self.classColumn is not None else None,
                                                                train_size=self.train_split,
                                                                test_size=self.test_split, shuffle=True)
            # Convert x_test and y_test a DataFrame
            self.inputDatasetTest = pd.concat([x_test, y_test], axis=1)
        else:
            x_train, x_test = train_test_split(self.inputDataset[self.inputNames],
                                               train_size=self.train_split, test_size=self.test_split,
                                               shuffle=True)

            self.inputDatasetTest = x_test

        self.predictionsTest = self.pmmlModelLearner.predict(self.inputDatasetTest)  # Make predictions on the dataset

        # Create the output directory if it does not exist
        if not os.path.exists(self.outputDatasetFilePath):
            os.makedirs(self.outputDatasetFilePath)

        if not self.exportOnlyPredictions:
            predictions_df = self.inputDatasetTest.copy()
            predictions_df = pd.concat([predictions_df, self.predictionsTest], axis=1)
            predictions_df.to_parquet(f'{self.outputDatasetFilePath}/Predictions_using_{self.modelName.name}.parquet',
                                      index=False)
            print_and_log("Predictions and dataset saved to a Parquet file")
        else:
            self.predictionsTest.to_parquet(f'{self.outputDatasetFilePath}/Only_predictions_using_'
                                            f'{self.modelName.name}.parquet', index=False)
            print_and_log("Only predictions saved to a PARQUET file")

    def save_test_metrics(self):
        """
        Save the test metrics to the PMMLModel class instance and export them to a PARQUET file if the attribute
        'export_test_metrics' is True
        """
        print_and_log("Testing model and saving metric results...")
        if self.algorithmName == 'classification':

            y_true = self.inputDatasetTest[self.classColumn]
            y_pred = self.predictionsTest[self.predictedClassColumn]
            y_true = pd.Categorical(y_true).codes
            y_pred = pd.Categorical(y_pred).codes

            accuracy = sklearn_metrics.accuracy_score(y_true, y_pred)
            precision = sklearn_metrics.precision_score(y_true, y_pred, average='macro')
            recall = sklearn_metrics.recall_score(y_true, y_pred, average='macro')
            f1 = sklearn_metrics.f1_score(y_true, y_pred, average='macro')
            # Save the metrics to the PMMLModel object
            self.metric_scores = pd.DataFrame({
                'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],
                'Score': [accuracy, precision, recall, f1]
            })

        elif self.algorithmName == 'regression':

            y_true = self.inputDatasetTest[self.classColumn]
            y_pred = self.predictionsTest[self.predictedClassColumn]

            mse = sklearn_metrics.mean_squared_error(y_true, y_pred)
            mae = sklearn_metrics.mean_absolute_error(y_true, y_pred)
            r2 = sklearn_metrics.r2_score(y_true, y_pred)
            median_ae = sklearn_metrics.median_absolute_error(y_true, y_pred)

            self.metric_scores = pd.DataFrame({
                'Metric': ['Mean Squared Error', 'R2 Score', 'Mean Absolute Error', 'Median Absolute Error'],
                'Score': [mse, r2, mae, median_ae]
            })

        elif self.algorithmName == 'clustering':
            cluster_names = self.predictionsTest['cluster_name']

            # Count the number of instances in each cluster
            cluster_counts = cluster_names.value_counts()

            self.metric_scores = pd.DataFrame({
                'Metric': ['Cluster Counts'],
                'Score': [cluster_counts.to_string()]
            })

            self.metric_scores_numeric = pd.DataFrame({
                'Metric': ['Cluster Counts'],
                'Score': [cluster_counts]
            })

        else:
            raise ValueError(f"{self.modelName.value.upper()} model not recognized")

        if self.export_test_metrics:
            if not os.path.exists(self.export_test_metrics_path):
                os.makedirs(self.export_test_metrics_path)

            self.metric_scores.to_parquet(f'{self.export_test_metrics_path}/Metric_scores_using_'
                                          f'{self.modelName.name}.parquet', index=False)
            print_and_log("Metric scores saved to a Parquet file")

    def train_and_validate_model(self):
        """
        Train and validate the model if the attribute 'validate_model' is True
        """
        print_and_log(f"Training and validating the {self.modelName.value.upper()} model...")

        model_validated = False

        # Split the dataset into train and test using train_test_split from sklearn
        y_test = None
        y_train = None
        if self.classColumn is not None:
            x_train, x_test, y_train, y_test = train_test_split(self.inputDataset[self.inputNames],
                                                                self.inputDataset[self.classColumn]
                                                                if self.classColumn is not None else None,
                                                                train_size=self.train_split,
                                                                test_size=self.test_split, shuffle=True)
        else:
            x_train, x_test = train_test_split(self.inputDataset[self.inputNames], train_size=self.train_split,
                                               test_size=self.test_split, shuffle=True)

        # Prepare the training data to convert categorical columns to numerical columns
        x_train = x_train.apply(lambda col: pd.Categorical(col).codes)
        x_test = x_test.apply(lambda col: pd.Categorical(col).codes)

        # Parse the PMML model to get the root element
        tree = ElementTreeXML.parse(self.pmml_model_filepath)
        root = tree.getroot()  # Get the root element
        xml_model_specification = root.find('.//{http://www.dmg.org/PMML-4_2}' + self.pmmlModelLearner.modelElement)

        validation_model = None
        # Train the model using the training dataset
        if self.modelName == ModelName.LINEAR_REGRESSION and self.algorithmName == 'regression':
            validation_model = LinearRegression()
            validation_model.fit(x_train, y_train)
        elif self.modelName == ModelName.DECISION_TREE and self.algorithmName == 'classification':
            validation_model = DecisionTreeClassifier()
            validation_model.fit(x_train, y_train)
        elif self.modelName == ModelName.DECISION_TREE and self.algorithmName == 'regression':
            validation_model = DecisionTreeRegressor()
            validation_model.fit(x_train, y_train)
        elif self.modelName == ModelName.NAIVE_BAYES:
            if xml_model_specification is not None:
                threshold = float(xml_model_specification.get('threshold'))
                validation_model = GaussianNB(var_smoothing=threshold)
                print("     * Using hiperparameters: threshold =", threshold)
                validation_model.fit(x_train, y_train)
            else:
                print_and_log("XML model specification not found")
        elif self.modelName == ModelName.MLP and self.algorithmName == 'classification':
            if xml_model_specification is not None:
                activation_function = xml_model_specification.get('activationFunction')
                validation_model = MLPClassifier(activation=activation_function)
                print("     * Using hiperparameters: activationFunction =", activation_function)
                validation_model.fit(x_train, y_train)
            else:
                print_and_log("XML model specification not found")
        elif self.modelName == ModelName.MLP and self.algorithmName == 'regression':
            if xml_model_specification is not None:
                activation_function = xml_model_specification.get('activationFunction')
                validation_model = MLPRegressor(activation=activation_function)
                print("     * Using hiperparameters: activationFunction =", activation_function)
                validation_model.fit(x_train, y_train)
            else:
                print_and_log("XML model specification not found")
        elif self.modelName == ModelName.K_MEANS and self.algorithmName == 'clustering':
            if xml_model_specification is not None:
                number_of_clusters = int(xml_model_specification.get('numberOfClusters'))
                validation_model = KMeans(n_clusters=number_of_clusters)
                validation_model.fit(x_train)
            else:
                print_and_log("XML model specification not found")
        else:
            raise ValueError(f"{self.modelName.value.upper()} model not recognized")

        print_and_log(f"{self.modelName.value.upper()} model has been TRAINED")

        # Make validation predictions
        self.validation_predictions = validation_model.predict(x_test)

        # Validate the model
        if self.algorithmName == 'classification':

            y_true = y_test
            y_pred = self.validation_predictions
            y_true = pd.Categorical(y_true).codes
            y_pred = pd.Categorical(y_pred).codes

            validated_accuracy = sklearn_metrics.accuracy_score(y_true, y_pred)
            validated_precision = sklearn_metrics.precision_score(y_true, y_pred, average='macro')
            validated_recall = sklearn_metrics.recall_score(y_true, y_pred, average='macro')
            validated_f1 = sklearn_metrics.f1_score(y_true, y_pred, average='macro')

            pretrained_model_accuracy = \
                self.metric_scores.loc[self.metric_scores['Metric'] == 'Accuracy', 'Score'].values[0]
            pretrained_model_precision = \
                self.metric_scores.loc[self.metric_scores['Metric'] == 'Precision', 'Score'].values[0]
            pretrained_model_recall = self.metric_scores.loc[self.metric_scores['Metric'] == 'Recall', 'Score'].values[
                0]
            pretrained_model_f1 = self.metric_scores.loc[self.metric_scores['Metric'] == 'F1 Score', 'Score'].values[0]

            print_and_log(f"Pretrained Model Accuracy: {pretrained_model_accuracy} - "
                  f"Validation Model Accuracy: {validated_accuracy}")
            print_and_log(f"Pretrained Model Precision: {pretrained_model_precision} - "
                  f"Validation Model Precision: {validated_precision}")
            print_and_log(f"Pretrained Model Recall: {pretrained_model_recall} - Validation Model Recall: {validated_recall}")
            print_and_log(f"Pretrained Model F1 Score: {pretrained_model_f1} - Validation Model F1 Score: {validated_f1}")

            # Check if the model is validated considering an epsilon error as a proportion
            if ((abs(pretrained_model_accuracy - validated_accuracy) < EPSILON) and
                    (abs(pretrained_model_precision - validated_precision) < EPSILON) and
                    (abs(pretrained_model_recall - validated_recall) < EPSILON) and
                    (abs(pretrained_model_f1 - validated_f1) < EPSILON)):
                model_validated = True

        elif self.algorithmName == 'regression':

            y_true = y_test
            y_pred = self.validation_predictions

            validated_mse = sklearn_metrics.mean_squared_error(y_true, y_pred)
            validated_mae = sklearn_metrics.mean_absolute_error(y_true, y_pred)
            validated_r2 = sklearn_metrics.r2_score(y_true, y_pred)
            validated_median_ae = sklearn_metrics.median_absolute_error(y_true, y_pred)

            pretrained_model_mse = \
                self.metric_scores.loc[self.metric_scores['Metric'] == 'Mean Squared Error', 'Score'].values[0]
            pretrained_model_mae = \
                self.metric_scores.loc[self.metric_scores['Metric'] == 'Mean Absolute Error', 'Score'].values[0]
            pretrained_model_r2 = self.metric_scores.loc[self.metric_scores['Metric'] == 'R2 Score', 'Score'].values[0]
            pretrained_model_median_ae = \
                self.metric_scores.loc[self.metric_scores['Metric'] == 'Median Absolute Error', 'Score'].values[0]

            print_and_log(f"Pretrained Model Mean Squared Error: {pretrained_model_mse} - "
                  f"Validation Model Mean Squared Error: {validated_mse}")
            print_and_log(f"Pretrained Model Mean Absolute Error: {pretrained_model_mae} - "
                  f"Validation Model Mean Absolute Error: {validated_mae}")
            print_and_log(f"Pretrained Model R2 Score: {pretrained_model_r2} - Validation Model R2 Score: {validated_r2}")
            print_and_log(f"Pretrained Model Median Absolute Error: {pretrained_model_median_ae} - "
                  f"Validation Model Median Absolute Error: {validated_median_ae}")

            # Check if the model is validated considering an epsilon error as a proportion
            if ((abs(pretrained_model_mse - validated_mse) < EPSILON) and
                    (abs(pretrained_model_r2 - validated_r2) < EPSILON) and
                    (abs(pretrained_model_mae - validated_mae) < EPSILON) and
                    (abs(pretrained_model_median_ae - validated_median_ae) < EPSILON)):
                model_validated = True

        elif self.algorithmName == 'clustering':

            # Count the number of instances in each cluster and compare with the original cluster counts
            validated_cluster_counts = pd.Series(self.validation_predictions).value_counts()
            pretrained_model_cluster_counts = \
                self.metric_scores_numeric.loc[self.metric_scores['Metric'] == 'Cluster Counts', 'Score'].values[0]
            print_and_log(f"Pretrained Model Cluster Counts: {pretrained_model_cluster_counts} \nValidation Model Cluster "
                  f"Counts:\n{validated_cluster_counts}")

            # Check if the model is validated considering an epsilon error
            if (pretrained_model_cluster_counts - validated_cluster_counts).abs().max() < EPSILON:
                model_validated = True
        else:
            raise ValueError(f"{self.modelName.value.upper()} model not recognized")

        if model_validated:
            print(f"{self.modelName.value.upper()} model has been VALIDATED\n")
        else:
            print(f"{self.modelName.value.upper()} model has NOT BEEN VALIDATED\n")

    def __str__(self):
        """
        String representation of the PMML model
        :return: string representation of the PMML model
        """
        return f"Algorithm type name: {self.algorithmName}\n" \
               f"Model name: {self.modelName.value.upper()}\n" \
               f"Input names: {self.inputNames}\n" \
               f"Output names: {self.outputNames}\n"
